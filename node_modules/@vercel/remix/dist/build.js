"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.build = void 0;
const ts_morph_1 = require("ts-morph");
const fs_1 = require("fs");
const path_1 = require("path");
const path_to_regexp_1 = require("path-to-regexp");
const build_utils_1 = require("@vercel/build-utils");
const static_config_1 = require("@vercel/static-config");
const nft_1 = require("@vercel/nft");
const config_1 = require("@remix-run/dev/dist/config");
const utils_1 = require("./utils");
const _require = eval('require');
const build = async ({ entrypoint, files, workPath, repoRootPath, config, meta = {}, }) => {
    const { installCommand, buildCommand } = config;
    await (0, build_utils_1.download)(files, workPath, meta);
    const mountpoint = (0, path_1.dirname)(entrypoint);
    const entrypointFsDirname = (0, path_1.join)(workPath, mountpoint);
    // Run "Install Command"
    const nodeVersion = await (0, build_utils_1.getNodeVersion)(entrypointFsDirname, undefined, config, meta);
    const spawnOpts = (0, build_utils_1.getSpawnOptions)(meta, nodeVersion);
    if (!spawnOpts.env) {
        spawnOpts.env = {};
    }
    const { cliType, lockfileVersion } = await (0, build_utils_1.scanParentDirs)(entrypointFsDirname);
    spawnOpts.env = (0, build_utils_1.getEnvForPackageManager)({
        cliType,
        lockfileVersion,
        nodeVersion,
        env: spawnOpts.env || {},
    });
    if (typeof installCommand === 'string') {
        if (installCommand.trim()) {
            console.log(`Running "install" command: \`${installCommand}\`...`);
            await (0, build_utils_1.execCommand)(installCommand, {
                ...spawnOpts,
                cwd: entrypointFsDirname,
            });
        }
        else {
            console.log(`Skipping "install" command...`);
        }
    }
    else {
        await (0, build_utils_1.runNpmInstall)(entrypointFsDirname, [], spawnOpts, meta, nodeVersion);
    }
    // Make `remix build` output production mode
    spawnOpts.env.NODE_ENV = 'production';
    // We need to patch the `remix.config.js` file to force some values necessary
    // for a build that works on either Node.js or the Edge runtime
    const remixConfigPath = (0, utils_1.findConfig)(entrypointFsDirname, 'remix.config');
    const renamedRemixConfigPath = remixConfigPath
        ? `${remixConfigPath}.original${(0, path_1.extname)(remixConfigPath)}`
        : undefined;
    if (remixConfigPath && renamedRemixConfigPath) {
        await fs_1.promises.rename(remixConfigPath, renamedRemixConfigPath);
        // Figure out if the `remix.config` file is using ESM syntax
        let isESM = false;
        try {
            _require(renamedRemixConfigPath);
        }
        catch (err) {
            if (err.code === 'ERR_REQUIRE_ESM') {
                isESM = true;
            }
            else {
                throw err;
            }
        }
        let patchedConfig;
        if (isESM) {
            patchedConfig = `import config from './${(0, path_1.basename)(renamedRemixConfigPath)}';
config.serverBuildTarget = undefined;
config.server = undefined;
config.serverModuleFormat = 'cjs';
config.serverPlatform = 'node';
config.serverBuildPath = 'build/index.js';
export default config;`;
        }
        else {
            patchedConfig = `const config = require('./${(0, path_1.basename)(renamedRemixConfigPath)}');
config.serverBuildTarget = undefined;
config.server = undefined;
config.serverModuleFormat = 'cjs';
config.serverPlatform = 'node';
config.serverBuildPath = 'build/index.js';
module.exports = config;`;
        }
        await fs_1.promises.writeFile(remixConfigPath, patchedConfig);
    }
    // Run "Build Command"
    let remixConfig;
    try {
        if (buildCommand) {
            (0, build_utils_1.debug)(`Executing build command "${buildCommand}"`);
            await (0, build_utils_1.execCommand)(buildCommand, {
                ...spawnOpts,
                cwd: entrypointFsDirname,
            });
        }
        else {
            const pkg = await (0, build_utils_1.readConfigFile)((0, path_1.join)(entrypointFsDirname, 'package.json'));
            if (hasScript('vercel-build', pkg)) {
                (0, build_utils_1.debug)(`Executing "yarn vercel-build"`);
                await (0, build_utils_1.runPackageJsonScript)(entrypointFsDirname, 'vercel-build', spawnOpts);
            }
            else if (hasScript('build', pkg)) {
                (0, build_utils_1.debug)(`Executing "yarn build"`);
                await (0, build_utils_1.runPackageJsonScript)(entrypointFsDirname, 'build', spawnOpts);
            }
            else {
                await (0, build_utils_1.execCommand)('remix build', {
                    ...spawnOpts,
                    cwd: entrypointFsDirname,
                });
            }
        }
        remixConfig = await (0, config_1.readConfig)(entrypointFsDirname);
    }
    finally {
        // Clean up our patched `remix.config.js` to be polite
        if (remixConfigPath && renamedRemixConfigPath) {
            await fs_1.promises.rename(renamedRemixConfigPath, remixConfigPath);
        }
    }
    const { serverBuildPath, routes: remixRoutes } = remixConfig;
    // Figure out which pages should be edge functions
    const edgePages = new Set();
    const project = new ts_morph_1.Project();
    for (const route of Object.values(remixRoutes)) {
        const routePath = (0, path_1.join)(remixConfig.appDirectory, route.file);
        const staticConfig = (0, static_config_1.getConfig)(project, routePath);
        const isEdge = staticConfig?.runtime === 'edge' ||
            staticConfig?.runtime === 'experimental-edge';
        if (isEdge) {
            edgePages.add(route);
        }
    }
    // This needs to happen before we run NFT to create the Node/Edge functions
    await Promise.all([
        ensureResolvable(entrypointFsDirname, repoRootPath, '@remix-run/server-runtime'),
        ensureResolvable(entrypointFsDirname, repoRootPath, '@remix-run/node'),
    ]);
    const [staticFiles, nodeFunction, edgeFunction] = await Promise.all([
        (0, build_utils_1.glob)('**', (0, path_1.join)(entrypointFsDirname, 'public')),
        createRenderNodeFunction(entrypointFsDirname, repoRootPath, serverBuildPath, nodeVersion),
        edgePages.size > 0
            ? createRenderEdgeFunction(entrypointFsDirname, repoRootPath, serverBuildPath)
            : undefined,
    ]);
    const output = staticFiles;
    const routes = [
        {
            src: '^/build/(.*)$',
            headers: { 'cache-control': 'public, max-age=31536000, immutable' },
            continue: true,
        },
        {
            handle: 'filesystem',
        },
    ];
    for (const route of Object.values(remixRoutes)) {
        // Layout routes don't get a function / route added
        const isLayoutRoute = Object.values(remixRoutes).some(r => r.parentId === route.id);
        if (isLayoutRoute)
            continue;
        // Build up the full request path
        let currentRoute = route;
        const pathParts = [];
        do {
            if (currentRoute.index)
                pathParts.push('index');
            if (currentRoute.path)
                pathParts.push(currentRoute.path);
            if (currentRoute.parentId) {
                currentRoute = remixRoutes[currentRoute.parentId];
            }
            else {
                currentRoute = undefined;
            }
        } while (currentRoute);
        const path = (0, path_1.join)(...pathParts.reverse());
        const isEdge = edgePages.has(route);
        const fn = isEdge && edgeFunction
            ? // `EdgeFunction` currently requires the "name" property to be set.
                // Ideally this property will be removed, at which point we can
                // return the same `edgeFunction` instance instead of creating a
                // new one for each page.
                new build_utils_1.EdgeFunction({
                    ...edgeFunction,
                    name: path,
                })
            : nodeFunction;
        output[path] = fn;
        // If this is a dynamic route then add a Vercel route
        const keys = [];
        // Replace "/*" at the end to handle "splat routes"
        const rePath = `/${path.replace(/\/\*$/, '/:params+')}`;
        const re = (0, path_to_regexp_1.pathToRegexp)(rePath, keys);
        if (keys.length > 0) {
            routes.push({
                src: re.source,
                dest: path,
            });
        }
    }
    // Add a 404 path for not found pages to be server-side rendered by Remix.
    // Use the edge function if one was generated, otherwise use Node.js.
    if (!output['404']) {
        output['404'] = edgeFunction
            ? new build_utils_1.EdgeFunction({ ...edgeFunction, name: '404' })
            : nodeFunction;
    }
    routes.push({
        src: '/(.*)',
        dest: '/404',
    });
    return { routes, output };
};
exports.build = build;
function hasScript(scriptName, pkg) {
    const scripts = (pkg && pkg.scripts) || {};
    return typeof scripts[scriptName] === 'string';
}
async function createRenderNodeFunction(entrypointDir, rootDir, serverBuildPath, nodeVersion) {
    const files = {};
    const relativeServerBuildPath = (0, path_1.relative)(rootDir, serverBuildPath);
    const handler = (0, path_1.join)((0, path_1.dirname)(relativeServerBuildPath), 'server-node.mjs');
    const handlerPath = (0, path_1.join)(rootDir, handler);
    // Copy the `server-node.mjs` file into the "build" directory
    const sourceHandlerPath = (0, path_1.join)(__dirname, '../server-node.mjs');
    await fs_1.promises.copyFile(sourceHandlerPath, handlerPath);
    // Trace the handler with `@vercel/nft`
    const trace = await (0, nft_1.nodeFileTrace)([handlerPath], {
        base: rootDir,
        processCwd: entrypointDir,
    });
    for (const warning of trace.warnings) {
        (0, build_utils_1.debug)(`Warning from trace: ${warning.message}`);
    }
    for (const file of trace.fileList) {
        files[file] = await build_utils_1.FileFsRef.fromFsPath({ fsPath: (0, path_1.join)(rootDir, file) });
    }
    const fn = new build_utils_1.NodejsLambda({
        files,
        handler,
        runtime: nodeVersion.runtime,
        shouldAddHelpers: false,
        shouldAddSourcemapSupport: false,
        operationType: 'SSR',
        experimentalResponseStreaming: true,
    });
    return fn;
}
async function createRenderEdgeFunction(entrypointDir, rootDir, serverBuildPath) {
    const files = {};
    const relativeServerBuildPath = (0, path_1.relative)(rootDir, serverBuildPath);
    const handler = (0, path_1.join)((0, path_1.dirname)(relativeServerBuildPath), 'server-edge.mjs');
    const handlerPath = (0, path_1.join)(rootDir, handler);
    // Copy the `server-edge.mjs` file into the "build" directory
    const sourceHandlerPath = (0, path_1.join)(__dirname, '../server-edge.mjs');
    await fs_1.promises.copyFile(sourceHandlerPath, handlerPath);
    // Trace the handler with `@vercel/nft`
    const trace = await (0, nft_1.nodeFileTrace)([handlerPath], {
        base: rootDir,
        processCwd: entrypointDir,
        conditions: ['worker', 'browser'],
        async readFile(fsPath) {
            let source;
            try {
                source = await fs_1.promises.readFile(fsPath);
            }
            catch (err) {
                if (err.code === 'ENOENT' || err.code === 'EISDIR') {
                    return null;
                }
                throw err;
            }
            if ((0, path_1.basename)(fsPath) === 'package.json') {
                // For Edge Functions, patch "main" field to prefer "browser" or "module"
                const pkgJson = JSON.parse(source.toString());
                for (const prop of ['browser', 'module']) {
                    const val = pkgJson[prop];
                    if (typeof val === 'string') {
                        pkgJson.main = val;
                        // Return the modified `package.json` to nft
                        source = JSON.stringify(pkgJson);
                        break;
                    }
                }
            }
            return source;
        },
    });
    for (const warning of trace.warnings) {
        (0, build_utils_1.debug)(`Warning from trace: ${warning.message}`);
    }
    for (const file of trace.fileList) {
        files[file] = await build_utils_1.FileFsRef.fromFsPath({ fsPath: (0, path_1.join)(rootDir, file) });
    }
    const fn = new build_utils_1.EdgeFunction({
        files,
        deploymentTarget: 'v8-worker',
        name: 'render',
        entrypoint: handler,
    });
    return fn;
}
async function ensureResolvable(start, base, pkgName) {
    try {
        const resolvedPath = _require.resolve(pkgName, { paths: [start] });
        if (!(0, path_1.relative)(base, resolvedPath).startsWith(`..${path_1.sep}`)) {
            // Resolved path is within the root of the project, so all good
            (0, build_utils_1.debug)(`"${pkgName}" resolved to '${resolvedPath}'`);
            return;
        }
    }
    catch (err) {
        if (err.code !== 'MODULE_NOT_FOUND') {
            throw err;
        }
    }
    // If we got to here then `pkgName` was not resolvable up to the root
    // of the project. Try a couple symlink tricks, otherwise we'll bail.
    // Attempt to find the package in `node_modules/.pnpm` (pnpm)
    const pnpmDir = await (0, build_utils_1.walkParentDirs)({
        base,
        start,
        filename: 'node_modules/.pnpm',
    });
    if (pnpmDir) {
        const prefix = `${pkgName.replace('/', '+')}@`;
        const packages = await fs_1.promises.readdir(pnpmDir);
        const match = packages.find(p => p.startsWith(prefix));
        if (match) {
            const pkgDir = (0, path_1.join)(pnpmDir, match, 'node_modules', pkgName);
            const symlinkPath = (0, path_1.join)(pnpmDir, '..', pkgName);
            const symlinkDir = (0, path_1.dirname)(symlinkPath);
            const symlinkTarget = (0, path_1.relative)(symlinkDir, pkgDir);
            await fs_1.promises.mkdir(symlinkDir, { recursive: true });
            await fs_1.promises.symlink(symlinkTarget, symlinkPath);
            console.warn(`WARN: Created symlink for "${pkgName}". To silence this warning, add "${pkgName}" to "dependencies" in your \`package.json\` file.`);
            return;
        }
    }
    // Attempt to find the package in `node_modules/.store` (npm 9+ linked mode)
    const npmDir = await (0, build_utils_1.walkParentDirs)({
        base,
        start,
        filename: 'node_modules/.store',
    });
    if (npmDir) {
        const prefix = `${(0, path_1.basename)(pkgName)}@`;
        const prefixDir = (0, path_1.join)(npmDir, (0, path_1.dirname)(pkgName));
        const packages = await fs_1.promises.readdir(prefixDir);
        const match = packages.find(p => p.startsWith(prefix));
        if (match) {
            const pkgDir = (0, path_1.join)(prefixDir, match, 'node_modules', pkgName);
            const symlinkPath = (0, path_1.join)(npmDir, '..', pkgName);
            const symlinkDir = (0, path_1.dirname)(symlinkPath);
            const symlinkTarget = (0, path_1.relative)(symlinkDir, pkgDir);
            await fs_1.promises.mkdir(symlinkDir, { recursive: true });
            await fs_1.promises.symlink(symlinkTarget, symlinkPath);
            console.warn(`WARN: Created symlink for "${pkgName}". To silence this warning, add "${pkgName}" to "dependencies" in your \`package.json\` file.`);
            return;
        }
    }
    throw new Error(`Failed to resolve "${pkgName}". To fix this error, add "${pkgName}" to "dependencies" in your \`package.json\` file.`);
}
//# sourceMappingURL=build.js.map